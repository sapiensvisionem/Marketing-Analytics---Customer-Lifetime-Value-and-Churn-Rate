{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Journey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to do?\n",
    "optimize customer journeys which maximize their satisfaction and lifetime value. predict customer churn and interpret its drivers, measure, and forecast customer lifetime value, and finally, build customer segments based on their product purchase patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "    use customer data from a telecom company to predict churn, construct a recency-frequency-monetary dataset from an online retailer for customer lifetime value prediction, and build customer segments from product purchase data from a grocery shop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions we want to answer using machine learning:\n",
    "    1. Which customers will churn? (classification)\n",
    "        : collect data on purchase patterns prior to churning\n",
    "    2. Which customers will buy again? (classification)\n",
    "    3. How much will customers spend in the next 30 days? (regression)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explore the dataset and now know key elements of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "telco_raw = pd.read_csv('/Users/jihunlee/Desktop/telco.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID           object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges         object\n",
      "Churn                object\n",
      "dtype: object\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "customerID          7043\n",
      "gender                 2\n",
      "SeniorCitizen          2\n",
      "Partner                2\n",
      "Dependents             2\n",
      "tenure                73\n",
      "PhoneService           2\n",
      "MultipleLines          3\n",
      "InternetService        3\n",
      "OnlineSecurity         3\n",
      "OnlineBackup           3\n",
      "DeviceProtection       3\n",
      "TechSupport            3\n",
      "StreamingTV            3\n",
      "StreamingMovies        3\n",
      "Contract               3\n",
      "PaperlessBilling       2\n",
      "PaymentMethod          4\n",
      "MonthlyCharges      1585\n",
      "TotalCharges        6531\n",
      "Churn                  2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the data types of telco_raw dataset\n",
    "print(telco_raw.dtypes)\n",
    "\n",
    "# Print the header of telco_raw dataset\n",
    "print(telco_raw.head())\n",
    "\n",
    "# Print the number of unique values in each telco_raw column\n",
    "print(telco_raw.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate the categorical and numerical columns and are ready to transform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store customerID and Churn column names\n",
    "custid = ['customerID']\n",
    "target = ['Churn']\n",
    "\n",
    "# Store categorical column names names that have less than 5 unique values.\n",
    "categorical = telco_raw.nunique()[telco_raw.nunique() < 5].keys().tolist()\n",
    "\n",
    "# Remove target from the list of categorical variables\n",
    "categorical.remove(target[0])\n",
    "\n",
    "# Store numerical column names\n",
    "numerical = [x for x in telco_raw.columns if x not in custid + target + categorical]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform one-hot encoding on the categorical variables and then scale the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_raw['TotalCharges'] = pd.to_numeric(telco_raw['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding to categorical variables \n",
    "telco_raw = pd.get_dummies(data = telco_raw, columns = categorical, drop_first=True)\n",
    "\n",
    "# Initialize StandardScaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on numerical columns\n",
    "scaled_numerical = scaler.fit_transform(telco_raw[numerical])\n",
    "\n",
    "# Build a DataFrame from scaled_numerical\n",
    "scaled_numerical = pd.DataFrame(scaled_numerical, columns=numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_raw = telco_raw.drop(['tenure', 'MonthlyCharges', 'TotalCharges'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate by columns\n",
    "df = pd.concat([telco_raw, scaled_numerical], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build an end-to-end machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "# Split X and Y into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "# Ensure training dataset has only 75% of original X data\n",
    "print(train_X.shape[0] / X.shape[0])\n",
    "\n",
    "# Ensure testing dataset has only 25% of original X data\n",
    "print(test_X.shape[0] / X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree is a list of machine-learned if-else rules that decide in the telecom churn case, whether customers will churn or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7940841865756542"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model with max_depth set at 5\n",
    "from sklearn import tree\n",
    "mytree = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "treemodel = mytree.fit(train_X, train_Y)\n",
    "\n",
    "# Predict values on the testing data\n",
    "pred_Y = treemodel.predict(test_X)\n",
    "\n",
    "# Measure model performance on testing data\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score\n",
    "accuracy_score(pred_Y, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a more complex decision tree with additional parameters to predict customer churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.824\n",
      "Test accuracy:  0.782\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 7, \n",
    "               criterion = 'gini', \n",
    "               splitter  = 'best')\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf = clf.fit(train_X, train_Y)\n",
    "\n",
    "# Predict the values on test dataset\n",
    "pred_Y = clf.predict(test_X)\n",
    "\n",
    "# Print accuracy values\n",
    "import numpy as np\n",
    "print(\"Training accuracy: \", np.round(clf.score(train_X, train_Y), 3)) \n",
    "print(\"Test accuracy: \", np.round(accuracy_score(test_Y, pred_Y), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Churn Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is churn?\n",
    "- Churn happens when a customer stops buying / engaging\n",
    "- The business context could be contractual or non-contractual\n",
    "- Sometimes churn can be viewed as either voluntary or involuntary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of churn\n",
    "1. Contractual (phone subscription, TV streaming subscription)\n",
    "2. Non-contractual (grocery shopping, online shopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling different types of churn\n",
    "- Non-contractual churn is harder to dene and model, as there's no explicit customer decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explore the churn distribution and split the data into training and testing before you proceed to modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Yes', 'No'}\n"
     ]
    }
   ],
   "source": [
    "# Print the unique Churn values\n",
    "print(set(df['Churn']))\n",
    "\n",
    "# Calculate the ratio size of each churn group\n",
    "df.groupby(['Churn']).size() / df.shape[0] * 100\n",
    "\n",
    "# Import the function for splitting data to train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test\n",
    "train, test = train_test_split(df, test_size = .25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate the features and target variables into different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store column names from `telcom` excluding target variable and customer ID\n",
    "cols = [col for col in df.columns if col not in custid + target]\n",
    "\n",
    "# Extract training features\n",
    "train_X = train[cols]\n",
    "\n",
    "# Extract training target\n",
    "train_Y = train[target]\n",
    "\n",
    "# Extract testing features\n",
    "test_X = test[cols]\n",
    "\n",
    "# Extract testing target\n",
    "test_Y = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit a logistic regression on the training part of the telecom churn dataset, and then predict labels on the unseen test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression on training data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict churn labels on testing data\n",
    "pred_test_Y = logreg.predict(test_X)\n",
    "\n",
    "# Calculate accuracy score on testing data\n",
    "test_accuracy = accuracy_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Print test accuracy score rounded to 4 decimals\n",
    "print('Test accuracy:', round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " run a logistic regression model on scaled data with L1 regularization to perform feature selection alongside model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Initialize logistic regression instance \n",
    "logreg = LogisticRegression(penalty='l1', C=0.025, solver='liblinear')\n",
    "\n",
    "# Fit the model on training data\n",
    "logreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict churn values on test data\n",
    "pred_test_Y = logreg.predict(test_X)\n",
    "\n",
    "# Print the accuracy score on test data\n",
    "print('Test accuracy:', round(accuracy_score(test_Y, pred_test_Y), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune the C parameter for the L1 regularization to discover the one which reduces model complexity while still maintaining good model performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list C has been created with the possible values. The l1_metrics array has been built with 3 columns, with the first being the C values, and the next two being placeholders for non-zero coefficient counts and the recall score of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               C  Non-Zero Coeffs    Recall\n",
      "0  2.237494e-314             18.0  0.519651\n",
      "1  2.237494e-314             22.0  0.532751\n",
      "2  2.237494e-314             24.0  0.539301\n",
      "3  2.237494e-314             24.0  0.539301\n",
      "4  2.237494e-314             20.0  0.541485\n",
      "5  2.237494e-314             27.0  0.541485\n",
      "6  2.237494e-314             27.0  0.541485\n",
      "7  2.237494e-314             27.0  0.541485\n",
      "8  2.237494e-314             25.0  0.541485\n",
      "9  2.237497e-314             27.0  0.541485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jihunlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Run a for loop over the range of C list length\n",
    "from sklearn.metrics import recall_score \n",
    "C = np.linspace(0.1,1,10)\n",
    "l1_metrics = np.empty([len(C), 3])\n",
    "for index in range(0, len(C)):\n",
    "  # Initialize and fit Logistic Regression with the C candidate\n",
    "  logreg = LogisticRegression(penalty='l1', C=C[index], solver='liblinear')\n",
    "  logreg.fit(train_X, train_Y)\n",
    "  # Predict churn on the testing data\n",
    "  pred_test_Y = logreg.predict(test_X)\n",
    "  # Create non-zero count and recall score columns\n",
    "  l1_metrics[index,1] = np.count_nonzero(logreg.coef_)\n",
    "  l1_metrics[index,2] = recall_score(test_Y, pred_test_Y, pos_label='Yes')\n",
    "\n",
    "# Name the columns and print the array as pandas DataFrame\n",
    "col_names = ['C','Non-Zero Coeffs','Recall']\n",
    "print(pd.DataFrame(l1_metrics, columns=col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the coefficients of the logistic regression to understand what is driving churn to go up or down. Extract the logistic regression coefficients from your fitted model, and calculate their exponent to make them more interpretable. extracted and transformed logistic regression coefficients and can now understand which of them increase of decrease the odds of churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature  Coefficient  Exp_Coefficient\n",
      "27                                 tenure    -1.420911         0.241494\n",
      "22                      Contract_Two year    -1.409622         0.244236\n",
      "4                        PhoneService_Yes    -0.892115         0.409788\n",
      "21                      Contract_One year    -0.564353         0.568728\n",
      "10                     OnlineSecurity_Yes    -0.458129         0.632466\n",
      "16                        TechSupport_Yes    -0.447104         0.639477\n",
      "9      OnlineSecurity_No internet service    -0.381723         0.682684\n",
      "12                       OnlineBackup_Yes    -0.229143         0.795214\n",
      "3                          Dependents_Yes    -0.143077         0.866687\n",
      "14                   DeviceProtection_Yes    -0.069104         0.933230\n",
      "24  PaymentMethod_Credit card (automatic)    -0.050386         0.950862\n",
      "8                      InternetService_No    -0.010164         0.989888\n",
      "11       OnlineBackup_No internet service    -0.004534         0.995476\n",
      "13   DeviceProtection_No internet service    -0.003385         0.996621\n",
      "15        TechSupport_No internet service    -0.002475         0.997528\n",
      "19    StreamingMovies_No internet service    -0.001318         0.998683\n",
      "17        StreamingTV_No internet service    -0.000013         0.999987\n",
      "2                             Partner_Yes     0.014279         1.014381\n",
      "20                    StreamingMovies_Yes     0.045773         1.046837\n",
      "0                             gender_Male     0.055326         1.056885\n",
      "6                       MultipleLines_Yes     0.177996         1.194821\n",
      "1                         SeniorCitizen_1     0.235334         1.265332\n",
      "25         PaymentMethod_Electronic check     0.367000         1.443398\n",
      "7             InternetService_Fiber optic     0.374887         1.454828\n",
      "23                   PaperlessBilling_Yes     0.411374         1.508889\n",
      "28                         MonthlyCharges     0.424308         1.528532\n",
      "29                           TotalCharges     0.670860         1.955920\n"
     ]
    }
   ],
   "source": [
    "# Combine feature names and coefficients into pandas DataFrame\n",
    "feature_names = pd.DataFrame(train_X.columns, columns = ['Feature'])\n",
    "log_coef = pd.DataFrame(np.transpose(logreg.coef_), columns = ['Coefficient'])\n",
    "coefficients = pd.concat([feature_names, log_coef], axis = 1)\n",
    "\n",
    "# Calculate exponent of the logistic regression coefficients\n",
    "coefficients['Exp_Coefficient'] = np.exp(coefficients['Coefficient'])\n",
    "\n",
    "# Remove coefficients that are equal to zero\n",
    "coefficients = coefficients[coefficients['Coefficient']!=0]\n",
    "\n",
    "# Print the values sorted by the exponent coefficient\n",
    "print(coefficients.sort_values(by=['Exp_Coefficient']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit a decision tree on the training set of the telecom dataset, and then predict labels on the unseen testing data, and calculate the accuracy of your model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize decision tree classifier\n",
    "mytree = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the decision tree on training data\n",
    "mytree.fit(train_X, train_Y)\n",
    "\n",
    "# Predict churn labels on testing data\n",
    "pred_test_Y = mytree.predict(test_X)\n",
    "\n",
    "# Calculate accuracy score on testing data\n",
    "test_accuracy = accuracy_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Print test accuracy\n",
    "print('Test accuracy:', round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune the max_depth parameter of the decision tree to discover the one which reduces over-fitting while still maintaining good model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a for loop over the range of depth list length\n",
    "for index in range(0, len(depth_list)):\n",
    "  # Initialize and fit decision tree with the `max_depth` candidate\n",
    "  mytree = DecisionTreeClassifier(max_depth=depth_list[index])\n",
    "  mytree.fit(train_X, train_Y)\n",
    "  # Predict churn on the testing data\n",
    "  pred_test_Y = mytree.predict(test_X)\n",
    "  # Calculate the recall score \n",
    "  depth_tuning[index,1] = recall_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Name the columns and print the array as pandas DataFrame\n",
    "col_names = ['Max_Depth','Recall']\n",
    "print(pd.DataFrame(depth_tuning, columns=col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract the if-else rules from the decision tree and plot them to identify the main drivers of the churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export graphviz object from the trained decision tree \n",
    "exported = tree.export_graphviz(decision_tree=mytree, \n",
    "                                # Assign feature names\n",
    "                                out_file=None, feature_names=train_X.columns, \n",
    "                                # Set precision to 1 and add class names\n",
    "                                precision=1, class_names=['Not churn','Churn'], filled = True)\n",
    "\n",
    "# Call the Source function and pass the exported graphviz object\n",
    "graph = graphviz.Source(exported)\n",
    "\n",
    "# Display the decision tree\n",
    "display_image(\"/User/jihunlee/Desktop/decision_tree_rules.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLV Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is CLV?\n",
    "- Measurement of customer value\n",
    "- Can be historical or predicted\n",
    "- Multiple approaches, depends on business type\n",
    "- Some methods are formula-based, some are predictive and distribution based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Historical CLV\n",
    "- Sum revenue of all past transactions\n",
    "- Multiply by the profit margin\n",
    "- Alternatively - sum profit of all past transactions, if available\n",
    "\n",
    "Problems are:\n",
    "- does not account for tenure, retention and churn\n",
    "- does not account for new customers and their future revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic CLV\n",
    "- Multiply average revenue with profit margin to get average profit\n",
    "- Multiply it with average customer lifespan\n",
    "CLV = Avg. Revenue * Profit Margin * Avg. Lifespan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Granular CLV\n",
    "- Multiply average revenue per purchase with average frequency and with prot margin\n",
    "- Multiply it with average customer lifespan\n",
    "- Accounts for both average revenue per transaction and average frequency per period\n",
    "CLV = Avg. revenue per purchase * Avg. Frequency * Profit Margin * Avg. Lifespan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional CLV Formula\n",
    "- Multiply average revenue with profit margin\n",
    "- Multiple average prot with the retention to churn rate\n",
    "- Churn can be derived from retention and equals 1 minus retention rate\n",
    "- Accounts for customer loyalty, most popular approach\n",
    "CLV = Avg. Revenue * Profit Margin * Retention Rate/ Churn Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Cohort Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the monthly cohort activity dataset to calculate retention and churn values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cohort sizes from the first column of cohort_counts\n",
    "cohort_sizes = cohort_counts.iloc[:,0]\n",
    "\n",
    "# Calculate retention by dividing the counts with the cohort sizes\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "\n",
    "# Calculate churn\n",
    "churn = 1 - retention\n",
    "\n",
    "# Print the retention table\n",
    "print(retention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the overall mean retention and churn rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the .mean() method twice in a row (this is called \"chaining\") to calculate the overall mean. exclude the first month values (first column) from this calculation as they are constant given this is the first month the customers have been active therefore their retention will be 100% and churn will be 0% for all cohorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean retention rate\n",
    "retention_rate = retention.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Calculate the mean churn rate\n",
    "churn_rate = churn.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Print rounded retention and churn rates\n",
    "print('Retention rate: {:.2f}; Churn rate: {:.2f}'.format(retention_rate, churn_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the basic CLV which multiplies average monthly spent with the projected customer lifespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly spend per customer\n",
    "monthly_revenue = online.groupby(['CustomerID','InvoiceMonth'])['TotalSum'].sum().mean()\n",
    "\n",
    "# Calculate average monthly spend\n",
    "monthly_revenue = np.mean(monthly_revenue)\n",
    "\n",
    "# Define lifespan to 36 months\n",
    "lifespan_months = 36\n",
    "\n",
    "# Calculate basic CLV\n",
    "clv_basic = monthly_revenue * lifespan_months\n",
    "\n",
    "# Print the basic CLV value\n",
    "print('Average basic CLV is {:.1f} USD'.format(clv_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more granular data and can give a better customer lifetime value estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average revenue per invoice\n",
    "revenue_per_purchase = online.groupby(['InvoiceNo'])['TotalSum'].mean().mean()\n",
    "\n",
    "# Calculate average number of unique invoices per customer per month\n",
    "frequency_per_month = online.groupby(['CustomerID','InvoiceMonth'])['InvoiceNo'].nunique().mean()\n",
    "\n",
    "# Define lifespan to 36 months\n",
    "lifespan_months = 36\n",
    "\n",
    "# Calculate granular CLV\n",
    "clv_granular = revenue_per_purchase * frequency_per_month * lifespan_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate traditional CLV: most popular descriptive CLV models that accounts for the retention and churn rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly spend per customer\n",
    "monthly_revenue = online.groupby(['CustomerID','InvoiceMonth'])['TotalSum'].sum().mean()\n",
    "\n",
    "# Calculate average monthly retention rate\n",
    "retention_rate = retention.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Calculate average monthly churn rate\n",
    "churn_rate = 1 - retention_rate\n",
    "\n",
    "# Calculate traditional CLV \n",
    "clv_traditional = monthly_revenue * (retention_rate / churn_rate)\n",
    "\n",
    "# Print traditional CLV and the retention rate values\n",
    "print('Average traditional CLV is {:.1f} USD at {:.1f} % retention_rate'.format(clv_traditional, retention_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLV Regression on RFM Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build recency, frequency, monetary value and other customer level features.  These features capture highly predictive customer behavior patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the snapshot date\n",
    "NOW = dt.datetime(2011,11,1)\n",
    "\n",
    "# Calculate recency by subtracting current date from the latest InvoiceDate\n",
    "features = online_X.groupby('CustomerID').agg({\n",
    "  'InvoiceDate': lambda x: (NOW - x.max()).days,\n",
    "  # Calculate frequency by counting unique number of invoices\n",
    "  'InvoiceNo': pd.Series.nunique,\n",
    "  # Calculate monetary value by summing all spend values\n",
    "  'TotalSum': np.sum,\n",
    "  # Calculate average and total quantity\n",
    "  'Quantity': ['mean', 'sum']}).reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "features.columns = ['CustomerID', 'recency', 'frequency', 'monetary', 'quantity_avg', 'quantity_total']a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a pandas pivot table with customers as rows, invoice months as columns, and number of invoice counts as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pivot table counting invoices for each customer monthly\n",
    "cust_month_tx = pd.pivot_table(data=online, values='InvoiceNo',\n",
    "                               index=['CustomerID'], columns=['InvoiceMonth'],\n",
    "                               aggfunc=pd.Series.nunique, fill_value=0)\n",
    "\n",
    "# Store November 2011 data column name as a list\n",
    "target = ['2011-11']\n",
    "\n",
    "# Store target value as `Y`\n",
    "Y = cust_month_tx[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify the names of the target variable and the feature columns, extract the data, and split them into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store customer identifier column name as a list\n",
    "custid = ['CustomerID']\n",
    "\n",
    "# Select feature column names excluding customer identifier\n",
    "cols = [col for col in features.columns if col not in custid]\n",
    "\n",
    "# Extract the features as `X`\n",
    "X = features[cols]\n",
    "\n",
    "# Split data to training and testing\n",
    "trainX, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Root mean squared error (RMSE) - Square root ofthe average squared difference between prediction and actuals\n",
    "- Mean absolute error (MAE) - Average absolute difference between prediction and actuals\n",
    "- Mean absolute percentage error (MAPE) - Average percentage difference between prediction and actuals (actuals can't be zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the model on the training data, and predict values on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize linear regression instance\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit the model to training dataset\n",
    "linreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict the target variable for training data\n",
    "train_pred_Y = linreg.predict(train_X)\n",
    "\n",
    "# Predict the target variable for testing data\n",
    "test_pred_Y = linreg.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "measure the regression performance on both training and testing data with two metrics - root mean squared error and mean absolute error. measure how \"close\" are the model predictions compared to actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate root mean squared error on training data\n",
    "rmse_train = np.sqrt(mean_squared_error(train_Y, train_pred_Y))\n",
    "\n",
    "# Calculate mean absolute error on training data\n",
    "mae_train = mean_absolute_error(train_Y, train_pred_Y)\n",
    "\n",
    "# Calculate root mean squared error on testing data\n",
    "rmse_test = np.sqrt(mean_squared_error(test_Y, test_pred_Y))\n",
    "\n",
    "# Calculate mean absolute error on testing data\n",
    "mae_test = mean_absolute_error(test_Y, test_pred_Y)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('RMSE train: {}; RMSE test: {}\\nMAE train: {}, MAE test: {}'.format(rmse_train, rmse_test, mae_train, mae_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not all model coefficients are statistically significant and look at the model summary table to explore their significance. The statsmodels library provides this functionality. Print the model summary table, explore which variables have the p-value lower than 0.05 (i.e. lower than 5%) to make sure the coefficient is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `statsmodels.api` module\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Initialize model instance on the training data\n",
    "olsreg = sm.OLS(train_Y, train_X)\n",
    "\n",
    "# Fit the model\n",
    "olsreg = olsreg.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(olsreg.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
